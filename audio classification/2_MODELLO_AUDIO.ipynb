{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e55fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "PATH = '/content/drive/My Drive/DSIM/'\n",
    "data_path = PATH + 'dati/'\n",
    "dump_path = PATH + 'dumps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c9f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar(i,max,postText):\n",
    "    n_bar =10 #size of progress bar\n",
    "    j= i/max\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(f\"[{'=' * int(n_bar * j):{n_bar}s}] {int(100 * j)}%  {postText}\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8095c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(input, size):\n",
    "    output = input[0:min(size, input.shape[0])]\n",
    "    output = np.concatenate((output, np.zeros(size-output.shape[0])))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc(file_path, max_len=40):\n",
    "    seconds=3\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=44100)\n",
    "    wave = crop(wave, sr*seconds)\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=sr, n_fft=2048, hop_length=512, n_mfcc=40)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6207423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dump(dump_data):\n",
    "    with open(dump_data, \"rb\") as fp: \n",
    "        data=pickle.load(fp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05197bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extract_mfcc():\n",
    "\n",
    "dump_data = dump_path + \"dump_mfcc.txt\"\n",
    "if not os.path.isfile(dump_data):\n",
    "    data = []\n",
    "    count=0\n",
    "    for command in os.listdir(data_path):\n",
    "        track_perc = 1\n",
    "        data_gen = []\n",
    "    for track in os.listdir(os.path.join(data_path,command)):\n",
    "        try:\n",
    "            #carico la traccia \n",
    "            track= mfcc(data_path+'/'+command+'/'+track)\n",
    "            data.append([track, command,count])\n",
    "\n",
    "            #barra di caricamento %\n",
    "            printProgressBar(track_perc, len(os.listdir(os.path.join(data_path,command))), str(command))\n",
    "            track_perc+=1\n",
    "        except:\n",
    "            print(\"\\n An exception occurred: \", track)\n",
    "        print('----> done!' )\n",
    "        count+=1 \n",
    "\n",
    "    with open(dump_data, \"wb\") as fp: \n",
    "        pickle.dump(data, fp)\n",
    "    print(\"-----> \", dump_data, \"saved!\")\n",
    "else:\n",
    "    print('Restoring data from dump...\\n')\n",
    "    data = load_dump(dump_data)\n",
    "    print('Done!')\n",
    "\n",
    "return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_extract_mfcc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4dcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "\n",
    "df = pd.DataFrame(data, columns=['features','subj_comm', 'subj_comm_int'])\n",
    "df[['subject','command']] = df.subj_comm.str.split(expand=True, pat='_')\n",
    "df['davide'] = np.where(df.subject=='davide',1,0)\n",
    "df['gabriele'] = np.where(df.subject=='gabriele',1,0)\n",
    "df['laura'] = np.where(df.subject=='laura',1,0)\n",
    "\n",
    "X = np.array(df.features.tolist())\n",
    "\n",
    "y_davide = to_categorical(df.davide.values)\n",
    "y_gabriele = to_categorical(df.gabriele.values)\n",
    "y_laura = to_categorical(df.laura.values)\n",
    "\n",
    "dict_az = {\"data\": 0, \"ora\": 1, \"temperatura\":2}\n",
    "y_az = to_categorical(df.command.map(dict_az).values)\n",
    "\n",
    "X, y_laura, y_gabriele, y_davide, y_az = shuffle(X, y_laura, y_gabriele, y_davide, y_az)\n",
    "X = X.reshape(-1,40,259,1)\n",
    "\n",
    "return X, y_gabriele, y_laura, y_davide, y_az "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_laura, y_gabriele, y_davide, y_az = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bbc817",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_lau, y_test_lau = train_test_split(X, y_laura, test_size=0.2, random_state=14)\n",
    "X_train, X_test, y_train_g, y_test_g = train_test_split(X, y_gabriele, test_size=0.2, random_state=14)\n",
    "X_train, X_test, y_train_d, y_test_d = train_test_split(X, y_davide, test_size=0.2, random_state=14)\n",
    "X_train, X_test, y_train_az, y_test_az = train_test_split(X, y_az, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe50d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "dropout_rate=0.3\n",
    "kernel_size=(2,2)\n",
    "pooling_dim=(2,2)\n",
    "\n",
    "input_layer=Input(shape=(X.shape[1],X.shape[2],X.shape[3]))\n",
    "\n",
    "# NETWORK SPEAKER\n",
    "\n",
    "x= Conv2D(64, kernel_size=kernel_size, activation='relu')(input_layer)\n",
    "x= Conv2D(64, kernel_size=kernel_size, activation='relu')(x)\n",
    "x= Dropout(dropout_rate)(x)\n",
    "x= MaxPooling2D(pool_size=pooling_dim)(x)\n",
    "\n",
    "x= Conv2D(128, kernel_size=kernel_size, activation='relu')(x)\n",
    "x= Conv2D(128, kernel_size=kernel_size, activation='relu')(x)\n",
    "x= Dropout(dropout_rate)(x)\n",
    "x= MaxPooling2D(pool_size=pooling_dim)(x)\n",
    "\n",
    "x= Conv2D(256, kernel_size=kernel_size, activation='relu')(x)\n",
    "x= Conv2D(256, kernel_size=kernel_size, activation='relu')(x)\n",
    "x= Dropout(dropout_rate)(x)\n",
    "x= MaxPooling2D(pool_size=pooling_dim)(x)\n",
    "\n",
    "x= Flatten()(x)\n",
    "\n",
    "x= Dense(128, activation='relu')(x)\n",
    "x= Dropout(dropout_rate)(x)\n",
    "x= Dense(64, activation='relu')(x)\n",
    "x= Dropout(dropout_rate)(x)\n",
    "\n",
    "output_laura= Dense(y_laura.shape[1], activation='softmax', name='laura')(x)\n",
    "output_gabriele= Dense(y_gabriele.shape[1], activation='softmax', name='gabriele')(x)\n",
    "output_davide = Dense(y_davide.shape[1], activation='softmax', name='davide')(x)\n",
    "\n",
    "# NETWORK AZIONI\n",
    "\n",
    "x = Conv2D(64, kernel_size=kernel_size, activation='relu')(input_layer)\n",
    "x= Conv2D(64, kernel_size=kernel_size, activation='relu')(x)\n",
    "x= Dropout(dropout_rate)(x)\n",
    "x= MaxPooling2D(pool_size=pooling_dim)(x)\n",
    "\n",
    "x= Conv2D(128, kernel_size=kernel_size, activation='relu')(x)\n",
    "x= Conv2D(128, kernel_size=kernel_size, activation='relu')(x)\n",
    "x= Dropout(dropout_rate)(x)\n",
    "x= MaxPooling2D(pool_size=pooling_dim)(x)\n",
    "\n",
    "x= Flatten()(x)\n",
    "\n",
    "x= Dense(128, activation='relu')(x)\n",
    "x= Dropout(dropout_rate)(x)\n",
    "\n",
    "output_va = Dense(y_va.shape[1], activation='softmax', name='azione')(x)\n",
    "\n",
    "model = Model(input_layer, [output_laura,output_gabriele,output_davide,output_va])\n",
    "\n",
    "losses = {\"laura\": \"binary_crossentropy\",\n",
    "          \"gabriele\": \"binary_crossentropy\",\n",
    "          \"davide\": \"binary_crossentropy\",\n",
    "          \"azione\": \"categorical_crossentropy\"}\n",
    "\n",
    "model.compile(loss=losses,optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "fig = plt.figure(figsize=(20,10))\n",
    "#----------------- LAURA---------------------------\n",
    "fig.add_subplot(2,4,1)\n",
    "plt.plot(history.history['laura_accuracy'])\n",
    "plt.plot(history.history['az_laura_accuracy'])\n",
    "plt.title('model accuracy - LAURA')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "fig.add_subplot(2,4,5)\n",
    "plt.plot(history.history['laura_loss'])\n",
    "plt.plot(history.history['az_laura_loss'])\n",
    "plt.title('model loss - LAURA')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "#----------------- GABRIELE---------------------------\n",
    "fig.add_subplot(2,4,2)\n",
    "plt.plot(history.history['gabriele_accuracy'])\n",
    "plt.plot(history.history['az_gabriele_accuracy'])\n",
    "plt.title('model accuracy - GABRIELE')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "fig.add_subplot(2,4,6)\n",
    "plt.plot(history.history['gabriele_loss'])\n",
    "plt.plot(history.history['az_gabriele_loss'])\n",
    "plt.title('model loss - GABRIELE')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "#----------------- DAVIDE---------------------------\n",
    "fig.add_subplot(2,4,3)\n",
    "plt.plot(history.history['davide_accuracy'])\n",
    "plt.plot(history.history['az_davide_accuracy'])\n",
    "plt.title('model accuracy - DAVIDE')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "fig.add_subplot(2,4,7)\n",
    "plt.plot(history.history['davide_loss'])\n",
    "plt.plot(history.history['az_davide_loss'])\n",
    "plt.title('model loss - DAVIDE')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "#------------- AZIONE----------------------\n",
    "fig.add_subplot(2,4,4)\n",
    "plt.plot(history.history['azione_accuracy'])\n",
    "plt.plot(history.history['az_azione_accuracy'])\n",
    "plt.title('model accuracy - AZIONE')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "fig.add_subplot(2,4,8)\n",
    "plt.plot(history.history['azione_loss'])\n",
    "plt.plot(history.history['az_azione_loss'])\n",
    "plt.title('model loss - AZIONE')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed974b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93edd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,to_file='plot.png',show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,[y_train_lau, y_train_g, y_train_d, y_train_az], validation_data=(X_test, [y_test_lau, y_test_g, y_test_d, y_test_az]), batch_size=32, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b523544",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_list = [y_test_lau, y_test_g, y_test_d, y_test_va]\n",
    "names = ['Laura', 'Gabriele', 'Davide', 'Azione']\n",
    "pos = 0\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "for y in y_test_list:\n",
    "    print(\"\\n -\", names[pos])\n",
    "    y_pred_ = np.argmax(y_pred[pos], axis = 1)\n",
    "    y_test = np.argmax(y_test_list[pos], axis = 1)\n",
    "    print(classification_report(y_test, y_pred_, digits = 2))\n",
    "    pos+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PATH+'model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_6",
   "language": "python",
   "name": "python3_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
